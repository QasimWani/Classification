{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align:center;\">Let's classify Xenophobic tweets using a [Naive Bayes Classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) model from scratch</p>\n",
    "### <div style=\"text-align:center;font-size:1.2em;\">Author : <a style=\"color:#1da1f2 !important;text-decoration:none !important;\" href=\"https://linkedin.com/in/qasimwani/\">Qasim Wani</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align:center;font-weight:700;\">Here are some examples of [Xenophobic](https://en.wikipedia.org/wiki/Xenophobia) speech</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://miro.medium.com/max/1485/0*c8nQ_q3acJHeO_gq)\n",
    "![alt text](https://miro.medium.com/max/1495/1*gEGkXAA99FIVpoRSd7vIKQ.png)\n",
    "![alt text](https://miro.medium.com/max/1488/0*kcb5Rs9m9RL4CVue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"font-size:1.1em\">Hate speech is starting to become a major issue where social media is prevelant.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"[Louise Matsakis](https://twitter.com/lmatsakis?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor) of Wired explains that *only <span style=\"font-weight:900;\">38%</span> of hate-speech posts that Facebook removes are detected by AI.* \n",
    "This is mainly because there are so many types of hate speech, and the language used changes rapidly.\"\n",
    "<br>\n",
    "Source : [Abraham Starosta](https://medium.com/sculpt/xenophobic-tweets-78a9b316635)\n",
    "\n",
    ">**With that being said, let's classify Tweets based on a special type of hate-speech, known as Xenophobia**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 : Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two datasets, training and testing.\n",
    "\n",
    "#Extracting training\n",
    "df_train = pd.read_csv(\"xenophobia train.csv\")\n",
    "df_test  = pd.read_csv(\"xenophobia test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df_train.iloc[:,1])\n",
    "y_train = np.array(df_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(df_test.iloc[:, 1])\n",
    "y_test = np.array(df_test.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>To send them back where they come from you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A bunch of racists chanted send her back after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Who are the phony sources who do not exist? Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump didn't tell any one to send them back. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>In order for an unlawful Alien to have same Ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      1  To send them back where they come from you hav...\n",
       "1      2  A bunch of racists chanted send her back after...\n",
       "2      2  Who are the phony sources who do not exist? Th...\n",
       "3      1  Trump didn't tell any one to send them back. I...\n",
       "4      1  In order for an unlawful Alien to have same Ri..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what do you have to say about this? Illegal pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>send them back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Send her back Trump reverses course and backs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>How could you have quality of life if your pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Send them back, build the wall, fix the laws.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      1  what do you have to say about this? Illegal pr...\n",
       "1      1                                     send them back\n",
       "2      2  Send her back Trump reverses course and backs ...\n",
       "3      2  How could you have quality of life if your pre...\n",
       "4      1      Send them back, build the wall, fix the laws."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears as if the labels aren't clear. Let's assign <span style=\"color:red;\">1</span> as Xenophobic and <span style=\"color:red;\">-1</span> as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"label\"] = df_train[\"label\"].replace(1, 1).replace(2, -1)\n",
    "df_test[\"label\"] = df_test[\"label\"].replace(1, 1).replace(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>To send them back where they come from you hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>A bunch of racists chanted send her back after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>Who are the phony sources who do not exist? Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump didn't tell any one to send them back. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>In order for an unlawful Alien to have same Ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      1  To send them back where they come from you hav...\n",
       "1     -1  A bunch of racists chanted send her back after...\n",
       "2     -1  Who are the phony sources who do not exist? Th...\n",
       "3      1  Trump didn't tell any one to send them back. I...\n",
       "4      1  In order for an unlawful Alien to have same Ri..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what do you have to say about this? Illegal pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>send them back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>Send her back Trump reverses course and backs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>How could you have quality of life if your pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Send them back, build the wall, fix the laws.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             tweets\n",
       "0      1  what do you have to say about this? Illegal pr...\n",
       "1      1                                     send them back\n",
       "2     -1  Send her back Trump reverses course and backs ...\n",
       "3     -1  How could you have quality of life if your pre...\n",
       "4      1      Send them back, build the wall, fix the laws."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Let's check to see if we have any null data in our training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null objects in our training set:\n",
      " label     0\n",
      "tweets    0\n",
      "dtype: int64\n",
      "\n",
      "Null objects in our testing set:\n",
      " label     0\n",
      "tweets    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Null objects in our training set:\\n\",df_train.notnull().count()-df_train.isnull().count())\n",
    "print(\"\\nNull objects in our testing set:\\n\",df_test.notnull().count() - df_test.isnull().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's classify our dataframe into two numpy arrays:\n",
    "> **1.** xenophobic tweets\n",
    "<br><br>\n",
    "> **2.** non-xenophobic tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(df):\n",
    "    \"\"\"\n",
    "    This function accepts a pandas dataframe object.\n",
    "    It returns two classified np.array objects (xenophobic (1) and non-xenophobic (-1))\n",
    "    \n",
    "    Parameters:\n",
    "    df : a pandas dataframe object consisting of all tweets to be classified\n",
    "    \"\"\"\n",
    "    y = np.array(df[\"label\"])\n",
    "    X = np.array(df[\"tweets\"])\n",
    "    \n",
    "    xenophobic = []     # Xenophobic = 1\n",
    "    non_xenophobic = [] # non-xenophobic = -1\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        one_tweet = str(X[i]).lower().strip()\n",
    "        one_tweet = re.sub(r'[^a-zA-Z0-9\\s]', \"\", one_tweet)\n",
    "        if(y_train[i] == 1):\n",
    "            xenophobic.append(one_tweet)\n",
    "        else:\n",
    "            non_xenophobic.append(one_tweet)\n",
    "    return np.array(xenophobic), np.array(non_xenophobic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Xenophobic tweets : 7031\n",
      "Number of Training non-xenophobic tweets : 3029\n"
     ]
    }
   ],
   "source": [
    "xen_train, non_xen_train = classify(df_train)\n",
    "print(\"Number of Training Xenophobic tweets : {0}\\nNumber of Training non-xenophobic tweets : {1}\"\n",
    "      .format(len(xen_train), len(non_xen_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Testing Set Xenophobic tweets : 81\n",
      "Number of Testing Set non-xenophobic tweets : 38\n"
     ]
    }
   ],
   "source": [
    "xen_test, non_xen_test = classify(df_test)\n",
    "print(\"Number of Testing Set Xenophobic tweets : {0}\\nNumber of Testing Set non-xenophobic tweets : {1}\"\n",
    "      .format(len(xen_test), len(non_xen_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, in order to know which tweets classify as Xenophobic, we need to **tokenize words.**\n",
    "<br>\n",
    "> This will help us see the **most occuring words** in xenophobic/non-xenophobic speech.\n",
    "<br>\n",
    "> We will tokenize words from most occurring 1 words upto most occurring 4 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_tokenizer(data, n=3):\n",
    "    \"\"\"\n",
    "    This function finds the n most occurring words in our data.\n",
    "    Returns a list of sorted tuples of 500 most occurring words.\n",
    "    \n",
    "    Parameters: \n",
    "    1. n    : Int. Number of words to tokenize. By default, n = 3.\n",
    "    2. data : np.array() object. List of datapoints to tokenize.\n",
    "    \"\"\"\n",
    "    n_word_count = {}\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for i in range(len(data)):\n",
    "        n_grams = ngrams(word_tokenize(data[i]), n)\n",
    "#         tokenized = [word for word in n_grams if word not in stop_words] <-- Use this when ignoring stop_words\n",
    "        tokenized = [ ' '.join(grams) for grams in n_grams]\n",
    "        for tokens in tokenized:\n",
    "#             if(tokens not in stop_words): <-- Use this when ignoring stop_words\n",
    "            if(tokens not in n_word_count):\n",
    "                n_word_count[tokens] = 1\n",
    "            else:\n",
    "                n_word_count[tokens] += 1\n",
    "            \n",
    "    most_common = np.array(Counter.most_common(n_word_count))[:500]\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf_idf(words, size):\n",
    "    \"\"\"Calculates the term frequency of top 500 most common words in all tweets i.e.\n",
    "        Xenophobic or non-xenophobic.\n",
    "        \n",
    "        Returns a new list with the word, frequency, and occurance as a fraction\n",
    "        \n",
    "        Takes in two parameters: \n",
    "        1. words : a list of tuples consisting of most frequent words and their respective frequencies\n",
    "        2. size  : number of tweets in given class\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    new_list = []\n",
    "    for i in range(len(words)):\n",
    "        num = float(words[i][-1])\n",
    "        x = float(num/size)\n",
    "        a = list(words[i])\n",
    "        y = float(x)\n",
    "        y = x*float(np.log(1/y))\n",
    "        a.append(y)\n",
    "        new_list.append(a)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_n_tf_idf(n_start, n_end):\n",
    "    \"\"\"\n",
    "    Calculates the term frequency - inverse document frequency of the\n",
    "    n most frequent words\n",
    "    \n",
    "    Parameters : \n",
    "    n_start : number to start from (n_start is inclusive)\n",
    "    n_end   : number to end (n_end is exclusive)\n",
    "    Returns : a list of Text Document Matrices\n",
    "    \"\"\"\n",
    "    xen_all_tdm = []\n",
    "    non_xen_all_tdm = []\n",
    "    for i in range(n_start, n_end):\n",
    "        \n",
    "        n_sorted_xen = ngram_tokenizer(xen_train, i)\n",
    "        n_sorted_non_xen = ngram_tokenizer(non_xen_train, i)   \n",
    "        \n",
    "        non_xen_td_idf = calc_tf_idf(n_sorted_non_xen, len(non_xen_train))\n",
    "        xen_td_idf = calc_tf_idf(n_sorted_xen, len(xen_train))\n",
    "        \n",
    "        xen_all_tdm.append(xen_td_idf)\n",
    "        non_xen_all_tdm.append(non_xen_td_idf)\n",
    "        \n",
    "    return np.array(xen_all_tdm), np.array(non_xen_all_tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's calculate the TD-IDF for the first 500 most common tokenized words\n",
    "xen_TDM, non_xen_TDM = first_n_tf_idf(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's represent it into a pandas dataframe\n",
    "\n",
    "xen_df_TDM = pd.DataFrame(data=xen_TDM[0], columns=['Terms','Frequency','TF-IDF'])\n",
    "non_xen_df_TDM = pd.DataFrame(data=non_xen_TDM[0], columns=['Terms','Frequency','TF-IDF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='text-align:center;'>Sorting based on Frequencies</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>of</td>\n",
       "      <td>2655</td>\n",
       "      <td>0.3677517829652808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>her</td>\n",
       "      <td>2726</td>\n",
       "      <td>0.36735422851710353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>2736</td>\n",
       "      <td>0.36727694457368604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you</td>\n",
       "      <td>2410</td>\n",
       "      <td>0.36700217489288156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is</td>\n",
       "      <td>2403</td>\n",
       "      <td>0.3669303371454771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Terms Frequency               TF-IDF\n",
       "8     of      2655   0.3677517829652808\n",
       "7    her      2726  0.36735422851710353\n",
       "6      a      2736  0.36727694457368604\n",
       "9    you      2410  0.36700217489288156\n",
       "10    is      2403   0.3669303371454771"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xen_df_TDM.sort_values(by=\"TF-IDF\",ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>1088</td>\n",
       "      <td>0.3677761060974408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trump</td>\n",
       "      <td>1239</td>\n",
       "      <td>0.36565754523745114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>you</td>\n",
       "      <td>944</td>\n",
       "      <td>0.3633454581605677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chant</td>\n",
       "      <td>941</td>\n",
       "      <td>0.3631796090547336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.3616253017541022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Terms Frequency               TF-IDF\n",
       "9      is      1088   0.3677761060974408\n",
       "8   trump      1239  0.36565754523745114\n",
       "10    you       944   0.3633454581605677\n",
       "11  chant       941   0.3631796090547336\n",
       "7      of      1326   0.3616253017541022"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_xen_df_TDM.sort_values(by=\"TF-IDF\",ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <div style=\"text-align:center\"> Naive Bayes Classifier Formula</div>\n",
    "\n",
    "![alt text](https://blog.easysol.net/wp-content/uploads/2017/12/Image-1-1-600x169.png)\n",
    "\n",
    "### <div style=\"text-align:center\"> Let's understand what the above formula means in detail</div>\n",
    "> Here, P(A|B) is the posterior probability, i.e. the objective. \n",
    "In our case, P(A|B) is P(xenophobia|tweet)\n",
    "P(B|A) is the likelihood, i.e. P(tweet | xenophobia)\n",
    "P(A) referes to the prior probability, i.e. P(xenophobia)\n",
    "P(B) referes to the marginal probability, i.e. P(tweet)\n",
    "\n",
    "## <div style=\"text-align:center\"> Note about calculating likelihood probability:</div>\n",
    "> In order to calculate P(B | A), we need to use the product operator, Π\n",
    "> Here's an example of how it works\n",
    "![alt text](https://math.illinoisstate.edu/day/courses/old/305/contentsum07.gif)\n",
    "\n",
    "## <div style=\"text-align:center\">Xenophobic Tweet Naive Bayes Classifier</div>\n",
    "![alt text](https://pbs.twimg.com/media/EA93xLoUEAEUmWQ?format=jpg&name=small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior(likelihood, prior, marginal):\n",
    "    \"\"\"\n",
    "    Calculates the posterior probability of a tweet being xenophobic or not.\n",
    "    Return the posterior value (0 - 1)\n",
    "    Parameters:\n",
    "    1. likelihood : The likelihood probability (float : 0 - 1)\n",
    "    2. prior : The prior probability (float : 0 - 1)\n",
    "    3. marginal : The marginal probability (float : 0 - 1)\n",
    "    \"\"\"\n",
    "    num = float(likelihood * prior)\n",
    "    marginal = num/float(marginal)\n",
    "    return float(marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_marginal(word, _type,xen_tdm, non_xen_tdm):\n",
    "    \"\"\"\n",
    "    Calculates the marginal probability of a word.\n",
    "    Returns the marginal probability (0-1) as a float.\n",
    "    Parameters:\n",
    "    1. word : the word to calculate marginal probability for.\n",
    "    \"\"\"\n",
    "    \n",
    "    marginal_non = 1\n",
    "    marginal_xen = 1\n",
    "    for xen, non in zip(xen_tdm, non_xen_tdm):\n",
    "        if(xen[0] == word):\n",
    "            marginal_xen = float(xen[1])\n",
    "        if(non[0] == word):\n",
    "            marginal_non = float(xen[1])\n",
    "    \n",
    "    frequency = marginal_non + marginal_xen\n",
    "    marginal_non /= frequency\n",
    "    marginal_xen /= frequency\n",
    "    \n",
    "    if(_type == \"xen\"):\n",
    "        return float(marginal_xen)\n",
    "    elif(_type == \"non\"):\n",
    "        return float(marginal_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_naive_bayes(twt):\n",
    "    \"\"\"\n",
    "    Predicts if a tweet is Xenophobic or not.\n",
    "    \n",
    "    Returns 1 if Xenophobic; \n",
    "    Returns -1 if non-xenophobic;\n",
    "    \n",
    "    Also Returns the posterior of Xenophobic and non-xenophobic.\n",
    "    \n",
    "    Parameters:\n",
    "    1. tweet : tweet to calculate the posterior for. Type : np.array() [Split each word.]\n",
    "    \"\"\"\n",
    "    \n",
    "    tots_xen = 0\n",
    "    tots_non = 0\n",
    "    size = 0\n",
    "    i = 0\n",
    "    for (xen_tdm, non_xen_tdm) in zip(xen_TDM, non_xen_TDM):\n",
    "        i += 1\n",
    "        tweet = list(ngrams(word_tokenize(twt), i))\n",
    "    # Calculating the prior probability of Xen and non-xen tweet\n",
    "        size_xen = len(xen_tdm)\n",
    "        size_non = len(non_xen_tdm)\n",
    "        total_size = size_non + size_xen\n",
    "        prior_xen = float(size_xen/total_size)\n",
    "        prior_non = float(size_non/total_size)\n",
    "    #-----------------------------------------------------------\n",
    "        likelihood_xen = 1\n",
    "        likelihood_non = 1\n",
    "\n",
    "        marginal_xen = 1\n",
    "        marginal_non = 1\n",
    "\n",
    "        for word in tweet:\n",
    "            word = \" \".join(word)\n",
    "            for (checker_xen,checker_non) in zip(xen_tdm, non_xen_tdm):\n",
    "                if(checker_xen[0] == word):\n",
    "                    likelihood_xen *= float(checker_xen[-1])\n",
    "                    marginal_xen *= calculate_marginal(word, 'xen',xen_tdm, non_xen_tdm)\n",
    "                if(checker_non[0] == word):\n",
    "                    likelihood_non *= float(checker_non[-1])\n",
    "                    marginal_non *= calculate_marginal(word,\"non\",xen_tdm, non_xen_tdm)\n",
    "\n",
    "        posterior_xen = calculate_posterior(likelihood_xen, prior_xen, marginal_xen)\n",
    "        posterior_non = calculate_posterior(likelihood_non, prior_non, marginal_non)\n",
    "        tots_xen += abs(posterior_xen)\n",
    "        tots_non += abs(posterior_non)\n",
    "        size += 1\n",
    "        \n",
    "    XEN = float(tots_xen/size)\n",
    "    NON_XEN = float(tots_non/size)\n",
    "    \n",
    "    if(XEN >= NON_XEN):\n",
    "        return XEN,NON_XEN, -1\n",
    "    return XEN, NON_XEN, 1\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style='text-align:center;'>Validating our Model</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polish_text(text):\n",
    "    \"\"\"\n",
    "    Polished text by making it lowercase and removing punctuation.\n",
    "    Returns the polished rext.\n",
    "    Parameters:\n",
    "    1. text : text to polish\n",
    "    \"\"\"\n",
    "    sentence = str(text).lower().strip()\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9\\s]', \" \", sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(data):\n",
    "    \"\"\"\n",
    "    This function validates our Naive Bayes Model.\n",
    "    Returns the number of estimated Xenophobic and non-xenophobic tweets\n",
    "    Parameters:\n",
    "    1. data : dataset of tweets to classify. Type = np.array()\n",
    "    \"\"\"\n",
    "    xen = 0\n",
    "    non = 0\n",
    "    for i in range(len(data)):\n",
    "        tweet = polish_text(data[i])\n",
    "        _, _, result = one_naive_bayes(tweet)\n",
    "        if(result == True):\n",
    "            xen += 1\n",
    "        else:\n",
    "            non += 1\n",
    "            \n",
    "    return xen, non"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"text-align:center;\">Let's calculate the precision score of our training set:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the number of trained Xenophobic tweets and non xenophobc tweets\n",
    "xen_T, non_T = validation(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6996 3064 <-- Model Generated ||| Actual --> 7031 3029\n"
     ]
    }
   ],
   "source": [
    "print(xen_T, non_T, \"<-- Model Generated ||| Actual -->\", len(xen_train), len(non_xen_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision score : 99.5%\n"
     ]
    }
   ],
   "source": [
    "precision_score = (xen_T/len(xen_train))*100\n",
    "print(\"Training Precision score : {0:.3g}%\".format(precision_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style='text-align:center;'><span style=\"color:red;\">99.5% precision score. </span> Not bad for our training set. Hopefully, we didn't overfit 🙏😂<br><br><br>Let's validate our testing set now</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the number of test xenophobic tweets and non xenophobic tweets\n",
    "xen_TEST, non_TEST = validation(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Precision score : 97.4%\n"
     ]
    }
   ],
   "source": [
    "precision_score = (1 - ((non_TEST - len(non_xen_test))/len(non_xen_test)))*100\n",
    "print(\"Testing Set Precision score : {0:.3g}%\".format(precision_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style='text-align:center;'><span style=\"color:red;\">97.4% precision score</span> for our testing set!</div>\n",
    "### <div style='text-align:center;'>And that is why a Multinomial Naive Bayes Classifier is powerful for classifying text</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But before I conclude, let's validate a sample tweet from [another wesbite](https://www.humanrights.gov.au/our-work/examples-racist-material-internet):",
    "![alt text](https://pbs.twimg.com/media/EA9-jo3UIAAyQDj?format=jpg&name=medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xenophobic Content.\n",
      "Xenophobic Percent: 37.52657871080821%\n",
      "Non-Xenophobic content: 37.524267053139525%\n"
     ]
    }
   ],
   "source": [
    "racist_content = \"\"\"\n",
    "GET THE\n",
    "FUCK OUT OF OUR COUNTRY\n",
    "NIGGERS,SPICS,KIKES,SANDNIGGERS,ANDCHINKS are ALL the SHIT that makes\n",
    "our COUNTRY STINK\n",
    "\n",
    "\"\"\"\n",
    "x, n, _ = one_naive_bayes(racist_content)\n",
    "if(x > n):\n",
    "     print(\"Xenophobic Content.\\nXenophobic Percent: {}%\\nNon-Xenophobic content: {}%\".format(x*100, n*100))\n",
    "else:\n",
    "    print(\"Non-Xenophobic Content.\\nXenophic Percent: {}%\\nNon-Xenophobic content: {}%\".format(x*100, n*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style='text-align:center;'>As you can see, that was clearly maked as Xenophobic content.</div>\n",
    "### Now, let's check to see if the [following quote](http://www.wiseoldsayings.com/neighbors-quotes/) is categorized as Xenophobic or not.",
    "![alt text](https://pbs.twimg.com/media/EA901ciUYAAuq5f?format=jpg&name=medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Xenophobic Content.\n",
      "\n",
      "Xenophic Percent: 26.167131080473325%\n",
      "Non-Xenophobic content: 26.780867721054353%\n"
     ]
    }
   ],
   "source": [
    "peaceful_content = \"\"\"\n",
    "How you can have dreams when your neighbors have nightmares.\n",
    "\"\"\"\n",
    "xen2,non2,ret = one_naive_bayes(peaceful_content)\n",
    "if(xen2>non2):\n",
    "    print(\"Xenophobic Content.\\n\\nXenophobic Percent: {}%\\nNon-Xenophobic content: {}%\".format(xen2*100, non2*100))\n",
    "else:\n",
    "    print(\"Non-Xenophobic Content.\\n\\nXenophic Percent: {}%\\nNon-Xenophobic content: {}%\".format(xen2*100, non2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow me on [Github](https://github.com/QasimWani)",
    "#### <div style=\"text-align:center;color:blue;font-size:1.618em;\">Peace Out!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Note: The model usually takes 30 minutes to run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
