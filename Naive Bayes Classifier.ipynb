{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Spam/Ham SMS/Email detector from scratch using Naive Bayes Classifier\n",
    "### Author : Qasim Wani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection as skl\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam-ham', sep=\"\\t\")\n",
    "X = np.array(df.iloc[:,1])\n",
    "y = np.array(df.iloc[:,0])\n",
    "X_train, X_test, y_train, y_test = skl.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n..."
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_np = []\n",
    "ham_np = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i] = X_train[i].replace(\".\", \" \").replace(\"!\",\" \").replace(\",\",\" \").replace(\"?\",\" \")\n",
    "    one_mail = X_train[i].split(\" \")[:]\n",
    "    if(y_train[i] == 'ham'):\n",
    "        ham_np.append(one_mail)\n",
    "    else:\n",
    "        spam_np.append(one_mail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfiy_words_counter(data):\n",
    "    word_count = {}\n",
    "    fanboys = \"for|an|and|nor|but|or|yet|so|is|\"\n",
    "    for word in data:\n",
    "        for cc in word:\n",
    "            cc = cc.lower()\n",
    "            if fanboys.find(cc) == -1:\n",
    "                if(len(cc) > 1):\n",
    "                    if cc not in word_count:\n",
    "                        word_count[cc] = 1\n",
    "                    else:\n",
    "                        word_count[cc] += 1\n",
    "                \n",
    "    spam_most_common = Counter.most_common(word_count)[:2500]\n",
    "    return spam_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_classifier_word_counter = classfiy_words_counter(spam_np)\n",
    "\n",
    "ham_classifier_word_counter = classfiy_words_counter(ham_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurrence_calc(words, size):\n",
    "    \"\"\"Calculates the occurance of top 20 most common words in all emails for it's category i.e. spam/ham. \n",
    "        Returns a new list with the word, frequency, and occurance as a fraction\n",
    "        \n",
    "        Takes in two parameters: \n",
    "        1. words : a list of tuples consisting of most frequent words and their respective frequencies\n",
    "        2. size  : number of emails in given class (spam/ham for example)\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    new_list = []\n",
    "    for i in range(len(words)):\n",
    "        num = float(words[i][-1])\n",
    "        x = float(num/size)\n",
    "        a = list(words[i])\n",
    "        y = float(x)\n",
    "        a.append(y)\n",
    "        new_list.append(a)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_TDM = np.array(occurrence_calc(words=spam_classifier_word_counter, size=len(spam_np)))\n",
    "ham_TDM  = np.array(occurrence_calc(words=ham_classifier_word_counter, size=len(ham_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dataframe_TDM = pd.DataFrame(data=spam_TDM, columns=['Spam Email Terms','Frequency','Occurrence'])\n",
    "ham_dataframe_TDM = pd.DataFrame(data=ham_TDM, columns=['Ham Email Terms','Frequency','Occurrence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ham Email Terms</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>1241</td>\n",
       "      <td>0.3839727722772277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>1071</td>\n",
       "      <td>0.3313737623762376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>779</td>\n",
       "      <td>0.24102722772277227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>551</td>\n",
       "      <td>0.17048267326732675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me</td>\n",
       "      <td>531</td>\n",
       "      <td>0.16429455445544555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>my</td>\n",
       "      <td>505</td>\n",
       "      <td>0.15625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ham Email Terms Frequency           Occurrence\n",
       "0             you      1241   0.3839727722772277\n",
       "1              to      1071   0.3313737623762376\n",
       "2             the       779  0.24102722772277227\n",
       "3              in       551  0.17048267326732675\n",
       "4              me       531  0.16429455445544555\n",
       "5              my       505              0.15625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_dataframe_TDM.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam Email Terms</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>459</td>\n",
       "      <td>0.9161676646706587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>call</td>\n",
       "      <td>236</td>\n",
       "      <td>0.47105788423153694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>190</td>\n",
       "      <td>0.37924151696606784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your</td>\n",
       "      <td>180</td>\n",
       "      <td>0.3592814371257485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>free</td>\n",
       "      <td>161</td>\n",
       "      <td>0.3213572854291417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>135</td>\n",
       "      <td>0.2694610778443114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spam Email Terms Frequency           Occurrence\n",
       "0               to       459   0.9161676646706587\n",
       "1             call       236  0.47105788423153694\n",
       "2              you       190  0.37924151696606784\n",
       "3             your       180   0.3592814371257485\n",
       "4             free       161   0.3213572854291417\n",
       "5              the       135   0.2694610778443114"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_dataframe_TDM.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Naive Bayes Classifier Formula\n",
    "\n",
    "![alt text](https://blog.easysol.net/wp-content/uploads/2017/12/Image-1-1-600x169.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's understand what the above formula means in detail\n",
    "> Here, P(A|B) is the posterior probability, i.e. the objective. \n",
    "In our case, P(A|B) is P(spam|email)\n",
    "P(B|A) is the likelihood, i.e. P(email | spam)\n",
    "P(A) referes to the prior probability, i.e. P(spam)\n",
    "P(B) referes to the marginal probability, i.e. P(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note about calculating likelihood probability:\n",
    "> In order to calculate P(B | A), we need to use the product operator, Î \n",
    "> Here's an example of how it works\n",
    "![alt text](https://math.illinoisstate.edu/day/courses/old/305/contentsum07.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Naive Bayes Classifier\n",
    "![alt text](https://alexn.org/assets/img/spam-multiple-bayes-naive.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_individual_likelihood(word_check, text_document_matrix):\n",
    "    \"\"\"\n",
    "    Calculates the likelihood of a word in a dataset of spam/ham emails\n",
    "    \n",
    "    Parameters:\n",
    "    1. word_check : The word to calculate the probability for. Data type = any\n",
    "    2. text_document_matrix : Dataset to calculate the proability against. Data type = nx3 np.array() object\n",
    "    \n",
    "    Returns the likelihood as a probability (0 - 1)\n",
    "    \"\"\"\n",
    "    rows = text_document_matrix.shape[0]\n",
    "    \n",
    "    occurrence = 0\n",
    "    \n",
    "    for i in range(rows):\n",
    "        word = text_document_matrix[i, 0]\n",
    "        if(word == word_check):\n",
    "            occurrence = float(text_document_matrix[i, -1])\n",
    "    return occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_marginal(word_check, spam_set, ham_set, data_size):\n",
    "    \"\"\"\n",
    "    Calculates the marginal probability of a word in a dataset\n",
    "    Four (4) Required Parameters.\n",
    "    Parameters:\n",
    "    1. word_check : The word to calculate marginal probability for. Data type = ANY\n",
    "    2. spam_set   : Spam dataset to calculate the probability against. Data Type = nx3 np.array() object\n",
    "    3. ham_set    : Ham dataset to calculate the probability against. Data Type = nx3 np.array() object\n",
    "    4. data_size  : The size of the entire dataset (spam and ham included). Data Type = INT\n",
    "    \"\"\"\n",
    "    rows = spam_set.shape[0]\n",
    "    \n",
    "    frequency = 0\n",
    "    \n",
    "    for (spam,ham) in zip(spam_set, ham_set):\n",
    "        if(spam[0] == word_check):\n",
    "            frequency += int(spam[1])\n",
    "        if(ham[0] == word_check):\n",
    "            frequency += int(ham[1])\n",
    "    marginal = frequency/float(data_size)\n",
    "    return float(marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior(likelihood, prior, margin):\n",
    "    \"\"\"\n",
    "    Calculates the Posterior probability of an email being spam or ham.\n",
    "    Returns the posterior probability (0 - 1)\n",
    "    Accepts Three (3) required parameters.\n",
    "    Parameters:\n",
    "    1. likelihood : Probability of a list of words given it's spam/ham. Data Type = float\n",
    "    2. prior      : Probability of spam/ham. Data Type = float\n",
    "    3. margin     : Probability of list of words. Data Type = float\n",
    "    \"\"\"\n",
    "    numerator = likelihood*prior\n",
    "    posterior = float(numerator/margin)\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_point_naive_bayes(email, TDM_spam, TDM_ham, spam_size, ham_size):\n",
    "    \"\"\"\n",
    "    Calculates whether an email is spam or ham.\n",
    "    Takes in five (5) required parameters : \n",
    "    1. email      : email to classify as spam/ham. Takes in the email as a list of words\n",
    "    2. TDM_spam   : Term Document Matrix for spam emails. Takes in an n x 3 list.\n",
    "    3. TDM_ham    : Term Document Matrix for ham emails. Takes in an n x 3 list.\n",
    "    4. spam_size  : The number of all spam emails in the dataset.\n",
    "    5. ham_size   : The number of all ham emails in the dataset.\n",
    "    \n",
    "    returns 1 if spam, 0 if ham\n",
    "    \"\"\"\n",
    "    total_set = int(ham_size) + int(spam_size)\n",
    "    \n",
    "#------Calculating prior spam and prior ham-----\n",
    "    prior_spam = float(spam_size/total_set)\n",
    "    prior_ham = float(ham_size/total_set)\n",
    "# ----------------------------------------------\n",
    "    \n",
    "    \n",
    "    likelihood_spam = 1\n",
    "    likelihood_ham  = 1\n",
    "    \n",
    "    margin_ham = 1\n",
    "    margin_spam = 1\n",
    "    \n",
    "    frequency_spam = 1\n",
    "    frequency_ham  = 1\n",
    "    \n",
    "    for word in email:\n",
    "        if(word in TDM_ham[:,0]):\n",
    "            likelihood_ham *= calculate_individual_likelihood(word, TDM_ham)\n",
    "            margin_ham *= calculate_marginal(word, TDM_spam, TDM_ham, total_set)\n",
    "            \n",
    "        if(word in TDM_spam[:,0]):\n",
    "            likelihood_spam *= calculate_individual_likelihood(word, TDM_spam)\n",
    "            margin_spam *= calculate_marginal(word, TDM_spam, TDM_ham, total_set)\n",
    "        \n",
    "#     print(margin_ham, margin_spam)\n",
    "#     print(\"Prior\")\n",
    "#     print(prior_ham, prior_spam)\n",
    "    posterior_spam = calculate_posterior(likelihood=likelihood_spam, prior=prior_spam, margin=margin_spam)\n",
    "    posterior_ham  = calculate_posterior(likelihood=likelihood_ham, prior=prior_ham, margin=margin_ham)\n",
    "#     print(posterior_ham, posterior_spam)\n",
    "    if(posterior_ham >= posterior_spam):\n",
    "        return posterior_ham, posterior_spam, 0\n",
    "    else:\n",
    "        return posterior_ham, posterior_spam, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validiating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the performance of our Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(spam_size, ham_size, data, __type=\"Training\"):\n",
    "    \"\"\"\n",
    "    Validates the Naive Bayes model.\n",
    "    Doesn't return anything. Prints some statistics.\n",
    "    \n",
    "    Parameters :\n",
    "    1. spam_np : Number of spam SMS\n",
    "    2. ham_np  : Number of ham SMS\n",
    "    3. data    : The dataset to validate\n",
    "    4. __type  : 'Training' -or- 'Testing'. By default, __type = \"Training\"\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for em_one in data:\n",
    "        check_one_email = em_one.split(\" \")\n",
    "        _,_,classification = one_point_naive_bayes(check_one_email, spam_TDM, ham_TDM, spam_size, ham_size)\n",
    "        result.append(classification)\n",
    "    sp = 0\n",
    "    ha = 0\n",
    "    for cls in result:\n",
    "        if(cls == 0):\n",
    "            ha += 1\n",
    "        else:\n",
    "            sp += 1\n",
    "    print(\"Number of Model Detected Ham SMS : {0}\\nNumber of Model Detected Spam SMS : {1}\\n\".format(ha, sp))\n",
    "    print(\"Number of Actual Ham SMS : {0}\\nNumber of Actual Spam SMS : {1}\\n\".format(ham_size, spam_size))\n",
    "    training_percent = float(sp/spam_size)*100\n",
    "    if(__type == \"Training\"):\n",
    "        training_percent = float(ha/ham_size)*100\n",
    "        \n",
    "    print(\"{0} Set Classification :\\n{1}% of all SMS were classified correctly.\\n\".format(__type, training_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Model Detected Ham SMS : 2883\n",
      "Number of Model Detected Spam SMS : 850\n",
      "\n",
      "Number of Actual Ham SMS : 3232\n",
      "Number of Actual Spam SMS : 501\n",
      "\n",
      "Training Set Classification :\n",
      "89.20173267326733% of all SMS were classified correctly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training Set Performance\n",
    "model_validation(len(spam_np), len(ham_np), X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the performance of our Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_validation_hyper_params():\n",
    "    \"\"\"\n",
    "    This function is used to calculate recall score and precision used in validating the testing model only.\n",
    "    \n",
    "    Returns the size of the Ham and Spam SMS testing set.\n",
    "    \"\"\"\n",
    "    test_spam = []\n",
    "    test_ham = []\n",
    "    for i in range(len(X_test)):\n",
    "        one_mail = X_test[i].split(\" \")[:]\n",
    "        if(y_test[i] == 'ham'):\n",
    "            test_ham.append(one_mail)\n",
    "        else:\n",
    "            test_spam.append(one_mail)\n",
    "    return len(test_ham), len(test_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Model Detected Ham SMS : 354\n",
      "Number of Model Detected Spam SMS : 1485\n",
      "\n",
      "Number of Actual Ham SMS : 246\n",
      "Number of Actual Spam SMS : 1593\n",
      "\n",
      "Testing Set Classification :\n",
      "93.22033898305084% of all SMS were classified correctly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing Set Performance\n",
    "test_spam, test_ham = testing_validation_hyper_params()\n",
    "model_validation(test_spam, test_ham, X_test, \"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection:\n",
    "#####  As you can see, my training accuracy was nearly 89.2%\n",
    "#####  On the other hand, my testing accuracy was a whopping 93.2%\n",
    "\n",
    "> ####  Note : SciKit Learn's NaiveBayesClassifier GausianNB() had a recall score of 98%. Pretty close to my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating an actual email from my gmail spam folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://pbs.twimg.com/media/EAzk1DfVAAA2vk0?format=jpg&name=4096x4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outside_source_checker(data):\n",
    "    '''\n",
    "    Classifies an individual email/SMS as spam (1) or ham (0).\n",
    "    Returns void.\n",
    "    \n",
    "    Required Parameters:\n",
    "    1. data : email / SMS to classify\n",
    "    '''\n",
    "    # Classifying the email as Spam (1) or Ham (0)\n",
    "    posterior_ham, posterior_spam, res = one_point_naive_bayes(data, spam_TDM, ham_TDM, len(spam_np), len(ham_np))\n",
    "    if(res == 0):\n",
    "        print(\"\"\"Ham Email/SMS\\nResult Value : {2}\\nConfidence Level of Ham : {0}\\nConfidence Level of Spam : {1}\\n\n",
    "        Note : These confidence scores are not percentages since they haven't been normalized\"\"\"\n",
    "              .format(posterior_ham, posterior_spam, res))\n",
    "    else:\n",
    "        print(\"\"\"Spam Email/SMS detected\\nResult Value: {2}\\nConfidence Level of Ham : {0}\\nConfidence Level of Spam : {1}\\n\n",
    "        Note : These confidence scores are not percentages since they haven't been normalized\"\"\"\n",
    "              .format(posterior_ham, posterior_spam, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the email into a list of words\n",
    "\n",
    "email =\"\"\"\n",
    "Good day\n",
    "\n",
    "We are writing you in the matter of your application on a Careers jobboard for vacancy of Supply Chain Agent\n",
    "\n",
    "Job region: US, all states\n",
    "Job Type: Full-time, Permanent\n",
    "Pay range: $96,200.00 - $118,500.00 / Per Year\n",
    "\n",
    "Major Responsibilities:\n",
    "- Implement and prepare the typical project planning and monitoring process for all projects\n",
    "- Coordinate ongoing relationships with all suppliers in collaboration with the marketing department\n",
    "- Direct team work to meet the customer and project scope requirements\n",
    "- Develop comprehensive project schedule with regional team members\n",
    "- Produce regular reports and statistics on a weekly basis\n",
    "- Participate in various projects and make recommendations to meet market demands\n",
    "\n",
    "Key skills and qualifications:\n",
    "- Demonstrated staff role and management skills\n",
    "- Have an ability to do customer service\n",
    "- Be detail-oriented, experienced and resourceful\n",
    "- Working knowledge of Microsoft Office\n",
    "- Legal driver's license and Driver experience\n",
    "\"\"\".replace(\".\",\" \").replace(\"!\",\" \").replace(\"/\",\" \").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Email/SMS detected\n\n",
      "Result Value: 1\n",
      "Confidence Level of Ham : 0.013080060322194078\n",
      "Confidence Level of Spam : 21390633.41930753\n",
      "\n",
      "        Note : These confidence scores are not percentages since they haven't been normalized\n"
     ]
    }
   ],
   "source": [
    "outside_source_checker(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating a Whatsapp message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://pbs.twimg.com/media/EA0BAMnW4AA8vhc?format=jpg&name=medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_message = \"\"\"\n",
    "Don't think I mentioned this.\n",
    "I'll be sending out the site to my list of beta users once we finish the PWA.\n",
    "We want to be able to get feedback at that stage too before our VT launch.\n",
    "\"\"\".replace(\".\",\" \").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham Email/SMS\n\n",
      "Result Value : 0\n",
      "Confidence Level of Ham : 0.5024047380295416\n",
      "Confidence Level of Spam : 0.018384557032790103\n",
      "\n",
      "        Note : These confidence scores are not percentages since they haven't been normalized\n"
     ]
    }
   ],
   "source": [
    "outside_source_checker(text_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
